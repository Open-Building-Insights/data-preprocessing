{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Initial configuration\n",
    "\n",
    "#### To start working with this particular notebook, you need to provide necessary credential and settings\n",
    "#### Below is an template of configuration, which is necessary prepare aside of this notebook and copy & paste all content in triple quotes to the next cell's input field\n",
    "\n",
    "    \"\"\"\n",
    "    {\n",
    "    \"CLOUDANT_API_KEY\": \"xxx\",\n",
    "    \"CLOUDANT_URL\": \"xxx\",\n",
    "    \"UTILS_BUCKET\": \"notebook-utils-bucket\",\n",
    "    \"BUCKET_TIFF\": \"xxx\",\n",
    "    \"DB_NAME\": \"xxx\",\n",
    "    \"COS_ENDPOINT_URL\": \"xxx\",\n",
    "    \"COS_APIKEY\": \"xxx\",\n",
    "    \"TYPE_SOURCE_FILTER\": \"xxx\",\n",
    "    \"AREA_TRESHOLD\": \"0\"\n",
    "    }\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "\n",
    "# read config\n",
    "config_str = getpass.getpass('Enter your prepared config: ')\n",
    "config = json.loads(config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import ibm_boto3\n",
    "import threading\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "from shapely import wkb, wkt\n",
    "from pyproj import Geod\n",
    "from ibmcloudant.cloudant_v1 import CloudantV1, Document, BulkDocs\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from botocore.client import Config\n",
    "from tqdm import tqdm\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Geod object for geodetic calculations\n",
    "geod = Geod(ellps=\"WGS84\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize cloudant client\n",
    "def init_cloudant():\n",
    "    authenticator = IAMAuthenticator(config[\"CLOUDANT_API_KEY\"])\n",
    "    client = CloudantV1(authenticator=authenticator)\n",
    "    client.set_service_url(config[\"CLOUDANT_URL\"])      \n",
    "\n",
    "    return client  \n",
    "\n",
    "client = init_cloudant()\n",
    "# Initialize the IBM COS client\n",
    "cos_client = ibm_boto3.client(\n",
    "    service_name='s3',\n",
    "    ibm_api_key_id=config[\"COS_APIKEY\"],\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=config[\"COS_ENDPOINT_URL\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Cloudant db to retrieve data\n",
    "response = client.post_find(\n",
    "    db=config[\"DB_NAME\"],\n",
    "    selector={\n",
    "        \"properties.type_source\": \"osm\", # filter for OSM entries\n",
    "        \"_attachments\": {\"$exists\": True}, # filter only exists attachments\n",
    "        \"properties.osm_area_meters\": { \"$gt\": float(config[\"AREA_TRESHOLD\"])}\n",
    "    },\n",
    "    fields=[\"_id\", \n",
    "            \"properties.osm_id\",\n",
    "            \"properties.osm_type\", \n",
    "            \"properties.osm_fclass\", \n",
    "            \"properties.osm_geometry\", \n",
    "            \"properties.osm_area_meters\",\n",
    "            \"properties.osm_name\",\n",
    "            \"properties.osm_other_tags\",\n",
    "            \"properties.type\"\n",
    "            ],\n",
    ").get_result()\n",
    "\n",
    "pd.set_option(\"display.precision\", 7)\n",
    "\n",
    "# Put extracted and relevant information from Cloudant to a DataFrame\n",
    "data = []\n",
    "for doc in response['docs']:\n",
    "    item = [\n",
    "        doc['_id'].split(':')[1],\n",
    "        doc['_id'].split(':')[0],\n",
    "        doc['properties']['osm_id'],\n",
    "        doc['properties']['osm_type'],\n",
    "        doc['properties']['osm_fclass'],\n",
    "        doc['properties']['osm_geometry'],\n",
    "        doc['properties']['osm_area_meters'],\n",
    "        doc['properties']['osm_name'],\n",
    "        doc['properties']['osm_other_tags'],\n",
    "        doc['properties']['type']\n",
    "    ]\n",
    "    data.append(item)\n",
    "\n",
    "osm_df = pd.DataFrame(data=data, \n",
    "                         columns=[\n",
    "                             'latitude', \n",
    "                             'longitude',\n",
    "                             'osm_id',\n",
    "                             'osm_type',\n",
    "                             'osm_building',\n",
    "                             'geometry',\n",
    "                             'area_in_meters',\n",
    "                             'osm_name',\n",
    "                             'osm_other_tags',\n",
    "                             'type'\n",
    "                             ])\n",
    "# Define data types for columns in DF\n",
    "convert_dict = {\n",
    "                'latitude': float,  \n",
    "                'longitude': float,\n",
    "                'osm_id': int,\n",
    "                'osm_type': str,\n",
    "                'osm_building': str,\n",
    "                'geometry': str,\n",
    "                'area_in_meters': float,\n",
    "                'osm_name': str,\n",
    "                'osm_other_tags': str,\n",
    "                'type': str\n",
    "                }\n",
    "\n",
    "osm_df = osm_df.astype(convert_dict)\n",
    "# Add a new column indicationg the source of the footprint\n",
    "osm_df['footprint_source'] = ['osm' for _ in range(len(osm_df))]\n",
    "# Convert geometry to GeoSeries and create a GeoDataFrame\n",
    "osm_df['geometry'] = gpd.GeoSeries.from_wkt(osm_df['geometry'])\n",
    "osm_df = gpd.GeoDataFrame(osm_df, geometry=osm_df.geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>geometry</th>\n",
       "      <th>bf_source</th>\n",
       "      <th>confidence</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>74.0610576</td>\n",
       "      <td>21.8987824</td>\n",
       "      <td>74.06105762275592:21.89878235572773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>73.9480130</td>\n",
       "      <td>21.8379369</td>\n",
       "      <td>73.94801304848016:21.837936926917244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23.0</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>74.0934640</td>\n",
       "      <td>21.8502398</td>\n",
       "      <td>74.09346402189675:21.850239797624493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>74.0666540</td>\n",
       "      <td>21.8763123</td>\n",
       "      <td>74.06665399498027:21.87631233327315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.0</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x07\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>74.0133757</td>\n",
       "      <td>21.8534511</td>\n",
       "      <td>74.01337569336263:21.85345113509525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20526</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>73.3442758</td>\n",
       "      <td>17.1522253</td>\n",
       "      <td>73.34427584530683:17.152225279252534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20784</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.8305</td>\n",
       "      <td>73.3128254</td>\n",
       "      <td>17.1482058</td>\n",
       "      <td>73.31282543483316:17.148205761341853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3007</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>73.3239783</td>\n",
       "      <td>18.8046588</td>\n",
       "      <td>73.32397828924084:18.80465878606797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3690</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.7424</td>\n",
       "      <td>73.4100863</td>\n",
       "      <td>18.8125250</td>\n",
       "      <td>73.4100862613181:18.812525025280287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6777</th>\n",
       "      <td>NaN</td>\n",
       "      <td>b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x0b\\x00...</td>\n",
       "      <td>google</td>\n",
       "      <td>0.8417</td>\n",
       "      <td>73.3320192</td>\n",
       "      <td>18.8054816</td>\n",
       "      <td>73.33201918741233:18.805481577980096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38609602 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Index                                           geometry bf_source  \\\n",
       "0        2.0  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...    google   \n",
       "1       21.0  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...    google   \n",
       "2       23.0  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...    google   \n",
       "3       39.0  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...    google   \n",
       "4       46.0  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x07\\x00...    google   \n",
       "...      ...                                                ...       ...   \n",
       "20526    NaN  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...    google   \n",
       "20784    NaN  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...    google   \n",
       "3007     NaN  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...    google   \n",
       "3690     NaN  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x05\\x00...    google   \n",
       "6777     NaN  b'\\x01\\x03\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x0b\\x00...    google   \n",
       "\n",
       "       confidence   longitude    latitude  \\\n",
       "0          0.6875  74.0610576  21.8987824   \n",
       "1          0.6875  73.9480130  21.8379369   \n",
       "2          0.6875  74.0934640  21.8502398   \n",
       "3          0.7500  74.0666540  21.8763123   \n",
       "4          0.7500  74.0133757  21.8534511   \n",
       "...           ...         ...         ...   \n",
       "20526      0.8579  73.3442758  17.1522253   \n",
       "20784      0.8305  73.3128254  17.1482058   \n",
       "3007       0.9085  73.3239783  18.8046588   \n",
       "3690       0.7424  73.4100863  18.8125250   \n",
       "6777       0.8417  73.3320192  18.8054816   \n",
       "\n",
       "                                         id  \n",
       "0       74.06105762275592:21.89878235572773  \n",
       "1      73.94801304848016:21.837936926917244  \n",
       "2      74.09346402189675:21.850239797624493  \n",
       "3       74.06665399498027:21.87631233327315  \n",
       "4       74.01337569336263:21.85345113509525  \n",
       "...                                     ...  \n",
       "20526  73.34427584530683:17.152225279252534  \n",
       "20784  73.31282543483316:17.148205761341853  \n",
       "3007    73.32397828924084:18.80465878606797  \n",
       "3690    73.4100862613181:18.812525025280287  \n",
       "6777   73.33201918741233:18.805481577980096  \n",
       "\n",
       "[38609602 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpd.options.display_precision = 7\n",
    "# Read data from Parquet into vida_df, drop index column\n",
    "vida_df = pd.read_parquet('Maharasta_buildings_clean.parquet')\n",
    "vida_df = vida_df.drop('Index', axis=1)\n",
    "\n",
    "# Convert geometry to Shapely geometries\n",
    "vida_df[\"geometry\"] = vida_df[\"geometry\"].apply(lambda g: shapely.from_wkb(g))\n",
    "# Fill NaN values in the confidence column with 0\n",
    "vida_df[\"confidence\"] = vida_df[\"confidence\"].fillna(0)\n",
    "# Calculate and add a new column to vida_df representing the area of each geometry in square meters\n",
    "vida_df['area_in_meters'] = vida_df[\"geometry\"].apply(lambda g: abs(geod.geometry_area_perimeter(g)[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to generate grid of tiles within a specified country bounding box and tile bounding box\n",
    "def generate_grid(\n",
    "                    country_bbox: list,\n",
    "                    tile_bbox: list,\n",
    "                    overlap=0.000\n",
    "                ):\n",
    "    # Calculate dimensions and amounts of rows and cols in the grid\n",
    "    row_col_dim = [\n",
    "      abs(tile_bbox[0][0] - tile_bbox[0][1]),\n",
    "      abs(tile_bbox[1][0] - tile_bbox[1][1]),\n",
    "    ]\n",
    "    \n",
    "    rows_cols = [\n",
    "      int(abs(country_bbox[0][0] - country_bbox[0][1]) // row_col_dim[0]) if abs(country_bbox[0][0] - country_bbox[0][1]) % row_col_dim[0] == 0 else int(abs(country_bbox[0][0] - country_bbox[0][1]) // row_col_dim[0]) + 1,\n",
    "      int(abs(country_bbox[1][0] - country_bbox[1][1]) // row_col_dim[1]) if abs(country_bbox[1][0] - country_bbox[1][1]) % row_col_dim[1] == 0 else int(abs(country_bbox[1][0] - country_bbox[1][1]) // row_col_dim[1]) + 1\n",
    "    ]\n",
    "    \n",
    "    columns_amount = rows_cols[0]\n",
    "    rows_amount = rows_cols[1]\n",
    "    \n",
    "    # Calculate width and height of each tile\n",
    "    tile_width = row_col_dim[0]\n",
    "    tile_height = row_col_dim[1]\n",
    "    # Calculate the overall w and h of the entire grid\n",
    "    tiff_height = abs(country_bbox[1][0] - country_bbox[1][1])\n",
    "    tiff_width = abs(country_bbox[0][0] - country_bbox[0][1])\n",
    "    \n",
    "    images_coords = []\n",
    "    \n",
    "    # Iterate over columns and rows to generate tile coords\n",
    "    for col_idx in range(1, columns_amount + 1):\n",
    "    \n",
    "        row_start = country_bbox[0][0] + max(tile_width * (col_idx - 1) - overlap, 0)\n",
    "\n",
    "        if col_idx != columns_amount:\n",
    "\n",
    "            row_limits = [row_start, country_bbox[0][0] + (tile_width * col_idx)]\n",
    "        elif col_idx == columns_amount:\n",
    "            row_limits = [row_start, country_bbox[0][0] + tiff_width]\n",
    "\n",
    "        for row_idx in range(1, rows_amount + 1):\n",
    "\n",
    "            col_start = country_bbox[1][0] + max(tile_height * (row_idx - 1) - overlap, 0)\n",
    "\n",
    "            if row_idx != rows_amount:\n",
    "                col_limits = [col_start, country_bbox[1][0] + (tile_height * row_idx)]\n",
    "            elif row_idx == rows_amount:\n",
    "                col_limits = [col_start, country_bbox[1][0] + tiff_height]\n",
    "\n",
    "            coords = [row_limits, col_limits]\n",
    "            \n",
    "            images_coords.append(coords)\n",
    "\n",
    "    return images_coords\n",
    "\n",
    "\n",
    "# Define a function to find polygons whose centroids fall within specified tiles\n",
    "def find_centroid_in_tile(all_country_tiles, polygons):\n",
    "    \n",
    "    polygons_in_tile = []\n",
    "    for tile_coords in all_country_tiles:\n",
    "        \n",
    "        tile_polygon = Polygon([\n",
    "                                (tile_coords[0][0], tile_coords[1][0]),\n",
    "                                (tile_coords[0][1], tile_coords[1][0]),\n",
    "                                (tile_coords[0][1], tile_coords[1][1]),\n",
    "                                (tile_coords[0][0], tile_coords[1][1]),\n",
    "                                (tile_coords[0][0], tile_coords[1][0])\n",
    "                                ])\n",
    "        \n",
    "        for centroid, poly in polygons.items():\n",
    "            if tile_polygon.contains(centroid):\n",
    "                polygons_in_tile.append(poly)\n",
    "                \n",
    "        return polygons_in_tile\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72.6526111, 15.6063595, 80.8977841, 22.0302694)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the polygon for Maharastra and convert it to a Shapely polygon\n",
    "polygon_string = json.load(open('maharasta_polygon.json'))['Maharastra']\n",
    "polygon = shapely.from_wkt(polygon_string)\n",
    "# Extract bounding box(bb) coords\n",
    "min_lon, min_lat, max_lon, max_lat = polygon.bounds\n",
    "country_bbox = [\n",
    "    [min_lon, max_lon],\n",
    "    [min_lat, max_lat]\n",
    "]\n",
    "# Default tile bb\n",
    "tile_bbox = [\n",
    "    [0, 1],\n",
    "    [0, 1]\n",
    "]\n",
    "# Generate a grid of tiles within specified bb and tile bounding box\n",
    "all_country_tiles = generate_grid(country_bbox, tile_bbox, overlap=0.05)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter buildings based on proximity (20 meteres)\n",
    "def filter_buildings(vida_filtered, building):\n",
    "    vida_matched = vida_filtered \\\n",
    "                    .where(\n",
    "                        (abs(vida_filtered.longitude - building.longitude) <= 0.001) &\n",
    "                        (abs(vida_filtered.latitude - building.latitude) <= 0.001) &\n",
    "                        (abs(vida_filtered.area_in_meters - building.area_in_meters) <= 25)\n",
    "                    ).dropna()\n",
    "                \n",
    "    vida_matched[\"osm_geometry\"] = [building.geometry for _ in range(len(vida_matched))]\n",
    "    vida_matched[\"osm_id\"] = [building.osm_id for _ in range(len(vida_matched))]\n",
    "    vida_matched[\"osm_building_area\"] = [building.area_in_meters for _ in range(len(vida_matched))]\n",
    "    vida_matched[\"intersection\"] = vida_matched[\"geometry\"].apply(lambda vida_geometry: float(vida_geometry.intersection(building.geometry).area/vida_geometry.area))\n",
    "\n",
    "    return vida_matched.where(vida_matched['intersection'] > 0).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to match buildings between VIDA and OSM datasets within bb\n",
    "def match_buildings(vida_df, osm_df, bbox):\n",
    "    \n",
    "    vida_filtered = vida_df \\\n",
    "        .where(\n",
    "            (vida_df.longitude >= bbox[0][0]) &\n",
    "            (vida_df.longitude <= bbox[0][1]) &\n",
    "            (vida_df.latitude >= bbox[1][0]) &\n",
    "            (vida_df.latitude <= bbox[1][1])\n",
    "        ).dropna()\n",
    "    \n",
    "    osm_filtered = osm_df \\\n",
    "        .where(\n",
    "            (osm_df.longitude >= bbox[0][0]) &\n",
    "            (osm_df.longitude <= bbox[0][1]) &\n",
    "            (osm_df.latitude >= bbox[1][0]) &\n",
    "            (osm_df.latitude <= bbox[1][1])\n",
    "        ).dropna()\n",
    "    \n",
    "    print(f\"\\n tile: {bbox} vida count: {len(vida_filtered)}, OSM count: {len(osm_filtered)}\")\n",
    "    \n",
    "    if len(osm_filtered) == 0 or len(vida_filtered) == 0:\n",
    "        \n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        # Initialize a list to store matched buildings\n",
    "        matched_buildings = []\n",
    "        # Iterate through OSM buildings and find matches in VIDA\n",
    "        for building in tqdm(osm_filtered.itertuples(), desc=\"Matching building\"):\n",
    "            try:\n",
    "                max_intersection_row = filter_buildings(vida_filtered, building)\n",
    "                matched_buildings.append(max_intersection_row)\n",
    "            \n",
    "            except Exception as e:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            # Concat the list of matched buildings into one DataFrame\n",
    "            df = pd.concat(matched_buildings)\n",
    "            print(f\"Buildings matched: {len(df)} of {len(osm_filtered)}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "# Iterate over all tiles and match buildings between VIDA and OSM\n",
    "for tile_idx, bbox in enumerate(all_country_tiles):\n",
    "    filtered_df = match_buildings(vida_df, osm_df, bbox)\n",
    "    if isinstance(filtered_df, pd.DataFrame):\n",
    "       dfs.append(filtered_df)\n",
    "# Concatenate list of DataFrames into one, sort by intersection and remove duplicates, then save to a Parquet file\n",
    "main_df = pd.concat(dfs).sort_values(by='intersection', ascending=True)\n",
    "df_to_save = main_df.drop_duplicates()\n",
    "df_to_save['geometry'] = df_to_save['geometry'].astype(str)\n",
    "df_to_save['osm_geometry'] = df_to_save['osm_geometry'].astype(str)\n",
    "df_to_save.to_parquet('matched_buildings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"matched_buildings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out VIDA buildings that were matched with OSM buildings\n",
    "vida_df_limited = vida_df\n",
    "vida_df_filtered = vida_df_limited.where(~vida_df_limited.id.isin(df.id)).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vida_part = vida_df_filtered\n",
    "df_vida_part = df_vida_part.rename(columns={\"bf_source\": \"footprint_source\"})\n",
    "osm_ml_df = osm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inner_faces(interiors):\n",
    "    total = 0\n",
    "    for interior in interiors:\n",
    "        total += len(interior.coords) - 1\n",
    "    return total\n",
    "\n",
    "def get_inner_perimeter(interiors):\n",
    "    geod = Geod(ellps=\"WGS84\")\n",
    "    total = 0\n",
    "    for interior in interiors:\n",
    "        total += abs(geod.geometry_area_perimeter(interior)[1])\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate original OSM and the remaining VIDA buildings dataframe\n",
    "result_df = pd.concat([osm_ml_df,df_vida_part], axis=0, ignore_index=True)\n",
    "\n",
    "# Fill NaN values with specified default values and drop long, lat and id columns\n",
    "values = {\"osm_id\": 0, \"confidence\": 0}\n",
    "result_df = result_df.fillna(value=values)\n",
    "result_df = result_df.fillna('')\n",
    "result_df = result_df.drop(['longitude', 'latitude', 'id'], axis=1)\n",
    "\n",
    "\n",
    "# Compute Perimeter\n",
    "result_df.insert(0,\"perimeter_in_meters\",0)\n",
    "result_df['perimeter_in_meters'] = result_df[\"geometry\"].apply(lambda g: (abs(geod.geometry_area_perimeter(shapely.from_wkb(g))[1]) + get_inner_perimeter(shapely.from_wkb(g).interiors)) if (shapely.from_wkb(g).geom_type == \"Polygon\") else (abs(geod.geometry_area_perimeter(g)[1])))\n",
    "\n",
    "# Compute number of faces\n",
    "result_df.insert(1,\"building_faces\",0)\n",
    "result_df['building_faces'] = result_df[\"geometry\"].apply(lambda g: (len(shapely.from_wkb(g).exterior.coords) - 1 + get_inner_faces(shapely.from_wkb(g).interiors)) if (shapely.from_wkb(g).geom_type == \"Polygon\") else 0)\n",
    "\n",
    "# Save the final merged DataFrame to a Parquet\n",
    "result_df.to_parquet('Maharashtra_OSM_VIDA.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
