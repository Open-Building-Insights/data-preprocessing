{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial configuration\n",
    "\n",
    "#### To start working with this particular notebook, you need to provide necessary credential and settings\n",
    "#### Below is an template of configuration, which is necessary prepare aside of this notebook and copy & paste all content in triple quotes to the next cell's input field\n",
    "\n",
    "    \"\"\"\n",
    "    {\n",
    "    \"CLOUDANT_API_KEY\": \"xxx\",\n",
    "    \"CLOUDANT_URL\": \"xxx\",\n",
    "    \"UTILS_BUCKET\": \"notebook-utils-bucket\",\n",
    "    \"BUCKET_TIFF\": \"xxx\",\n",
    "    \"DB_NAME\": \"xxx\",\n",
    "    \"COS_ENDPOINT_URL\": \"xxx\",\n",
    "    \"COS_APIKEY\": \"xxx\",\n",
    "    \"SQL_TABLE_NAME\": \"\",\n",
    "    \"COUNTRY\": \"\",\n",
    "    }\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read notebook configuration\n",
    "import getpass\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "config_str = getpass.getpass('Enter your prepared config: ')\n",
    "config = json.loads(config_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaydebeapi as jdbc\n",
    "import jpype\n",
    "import os\n",
    "import json\n",
    "import ijson\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "from tqdm import tqdm\n",
    "from shapely.wkt import dumps\n",
    "import traceback\n",
    "import ibm_boto3\n",
    "from botocore.client import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql_table_name = config[\"SQL_TABLE_NAME\"]\n",
    "sql_table_name = 'FEATURES_DB_KENYA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/42/bkr77x_n1qv118pt28lzd3380000gn/T/ipykernel_18839/2809985488.py:22: DeprecationWarning: jpype._core.isThreadAttachedToJVM is deprecated, use java.lang.Thread.isAttached instead\n",
      "  if jpype.isJVMStarted() and not jpype.isThreadAttachedToJVM():\n"
     ]
    }
   ],
   "source": [
    "# init S3 client in order to work with last tiff file version\n",
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "                              ibm_api_key_id=config[\"COS_APIKEY\"],\n",
    "                              config=Config(signature_version='oauth'),\n",
    "                              endpoint_url=config[\"COS_ENDPOINT_URL\"])\n",
    "\n",
    "def connect_to_db():\n",
    "    '''\n",
    "        Connect to the IBM DB2 database\n",
    "    '''\n",
    "    \n",
    "    jar = 'db2jcc4.jar'\n",
    "    os.environ['CLASSPATH'] = jar\n",
    "\n",
    "    args='-Djava.class.path=%s' % jar\n",
    "    jvm_path = jpype.getDefaultJVMPath()\n",
    "    try:\n",
    "        jpype.startJVM(jvm_path, args)\n",
    "    except Exception as e:\n",
    "        print('startJVM exception: ', e)\n",
    "        \n",
    "    if jpype.isJVMStarted() and not jpype.isThreadAttachedToJVM():\n",
    "        jpype.attachThreadToJVM()\n",
    "        jpype.java.lang.Thread.currentThread().setContextClassLoader(jpype.java.lang.ClassLoader.getSystemClassLoader())\n",
    "        \n",
    "    \n",
    "    conn = jdbc.connect(\n",
    "                'com.ibm.db2.jcc.DB2Driver',\n",
    "                config['DB2_CONNECTION_STRING'],\n",
    "                [config[\"DB2_USERNAME\"], config[\"DB2_PASSWORD\"]],\n",
    "                'db2jcc4.jar')\n",
    "\n",
    "    return conn\n",
    "\n",
    "conn = connect_to_db()\n",
    "curs = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4891"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a resource to be able to retrieve all the object in the bucket\n",
    "cos_client_resource = ibm_boto3.resource(service_name='s3',\n",
    "                              ibm_api_key_id=config[\"COS_APIKEY\"],\n",
    "                              config=Config(signature_version='oauth'),\n",
    "                              endpoint_url=config[\"COS_ENDPOINT_URL\"])\n",
    "\n",
    "# create a bucket instance\n",
    "bucket = cos_client_resource.Bucket(\"height-buildings-bucket-vol2\")\n",
    "\n",
    "# get all filenames from the tiffs bucket\n",
    "all_files = [i.key for i in bucket.objects.all()]\n",
    "\n",
    "target_parquets = [i for i in all_files if i.split('_')[0] in [config[\"REGION\"]]]\n",
    "\n",
    "len(target_parquets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights_parquets_folder = 'heights_parquets'\n",
    "\n",
    "if not os.path.exists(heights_parquets_folder):\n",
    "    os.makedirs(heights_parquets_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4891/4891 [18:48<00:00,  4.34it/s]  \n"
     ]
    }
   ],
   "source": [
    "for p in tqdm(target_parquets):\n",
    "    \n",
    "    cos_client.download_file(Bucket='height-buildings-bucket-vol2',Key=p,Filename=f'{heights_parquets_folder}/{p}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4891 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4891/4891 [13:53<00:00,  5.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30246892"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "files = os.listdir(heights_parquets_folder)\n",
    "dfs = []\n",
    "\n",
    "for f in tqdm(files, total=len(files)):\n",
    "    \n",
    "    df_curr = gpd.read_parquet(os.path.join(heights_parquets_folder, f))\n",
    "    try:\n",
    "        df_curr['height_isnull'] = df_curr.height_median.isnull()\n",
    "        df_curr = df_curr[df_curr['height_isnull'] == False]\n",
    "        df_curr['region'] = f.split('_')[0]\n",
    "        dfs.append(df_curr)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        dfs.append(df_curr)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "del dfs\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_df = df.drop_duplicates(subset='id')\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_df.to_parquet('Kenya_buildings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "\n",
    "    try:\n",
    "        '''\n",
    "         id,\n",
    "        latitude,\n",
    "        longitude,\n",
    "        area_in_meters,\n",
    "        polygon_coordinates,\n",
    "        footprint_source,\n",
    "        classification_source,\n",
    "        ml_confidence,\n",
    "        ml_model,\n",
    "        height,\n",
    "        height_median,\n",
    "        height_mean,\n",
    "        height_max,\n",
    "        tiff_file,\n",
    "        image_url,\n",
    "        classification_type,\n",
    "        osm_id,\n",
    "        osm_name,\n",
    "        osm_type,\n",
    "        osm_building,\n",
    "        osm_other_tags,\n",
    "        vida_confidence,\n",
    "        urban_split,\n",
    "        ghsl_smod,\n",
    "        floors,\n",
    "        gfa_in_meters,\n",
    "        perimeter_in_meters,\n",
    "        building_faces,\n",
    "        \n",
    "        elec_access_percent,\n",
    "        elec_consumption_kwh_month,\n",
    "        elec_consumption_std_kwh_month\n",
    "                                            '''\n",
    "        if isinstance(row.geometry, bytes):                    \n",
    "            polygon = shapely.from_wkb(row.geometry)\n",
    "        elif isinstance(row.geometry, str):\n",
    "            polygon = shapely.from_wkt(row.geometry)\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "        data =[\n",
    "            f'{round(float(row.longitude), 8)}:{round(float(row.latitude), 8)}',\n",
    "            round(float(row.latitude), 8),\n",
    "            round(float(row.longitude), 8),\n",
    "            round(row.area_in_meters, 4),\n",
    "            str(dumps(polygon, rounding_precision=8)),\n",
    "            row.footprint_source,\n",
    "            row.classification_source,\n",
    "            round(row.ml_confidence, 4),\n",
    "            row.ml_model,\n",
    "            float(row.height),\n",
    "            float(row.height_median),\n",
    "            float(row.height_mean),\n",
    "            float(row.height_max),\n",
    "            row.tiff_file,\n",
    "            row.image_url,\n",
    "            row.classification_type,\n",
    "            int(row.osm_id),\n",
    "            row.osm_name,\n",
    "            row.osm_type,\n",
    "            row.osm_building,\n",
    "            row.osm_other_tags,\n",
    "            row.vida_confidence,\n",
    "            row.urban_split,\n",
    "            row.ghsl_smod,\n",
    "            row.floors,\n",
    "            row.gfa_in_meters,\n",
    "            row.perimeter_in_meters,\n",
    "            row.building_faces,\n",
    "            \n",
    "            row.elec_access_percent,\n",
    "            row.elec_consumption_kwh_month,\n",
    "            row.elec_consumption_std_kwh_month\n",
    "        ]\n",
    "    \n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(traceback.format_exc())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALlows skipping if needed\n",
    "last_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = buildings_df[buildings_df['confidence'].isna()]\n",
    "\n",
    "\n",
    "# buildings_df['confidence'] = buildings_df['confidence'].fillna(0)\n",
    "# buildings_df['confidence'] = buildings_df['confidence'].fillna(0)\n",
    "buildings_df['ml_confidence'] = buildings_df['ml_confidence'].fillna(0)\n",
    "buildings_df['ml_model'] = buildings_df['ml_model'].fillna('')\n",
    "\n",
    "buildings_df['osm_id'] = buildings_df['osm_id'].fillna(0)\n",
    "buildings_df['osm_name'] = buildings_df['osm_name'].fillna('')\n",
    "buildings_df['osm_type'] = buildings_df['osm_type'].fillna('')\n",
    "buildings_df['osm_building'] = buildings_df['osm_building'].fillna('')\n",
    "buildings_df['osm_other_tags'] = buildings_df['osm_other_tags'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excepted_batches 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ingesting items: 100%|██████████| 31969027/31969027 [9:20:20<00:00, 950.88it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excepted_batches 0\n",
      "excepted_rows 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 750\n",
    "\n",
    "excepted_batches = []\n",
    "df_len = len(buildings_df)\n",
    "data_batch = []\n",
    "excepted_rows = []\n",
    "print('excepted_batches', len(excepted_batches))\n",
    "\n",
    "for idx, row in enumerate(tqdm(buildings_df.itertuples(), desc='Ingesting items', total=df_len)):\n",
    "    \n",
    "\n",
    "    if idx >= 0:\n",
    "        row = process_row(row)\n",
    "        if row != None:\n",
    "            data_batch.append(row)\n",
    "        else:\n",
    "            excepted_rows.append(row)\n",
    "        \n",
    "        if len(data_batch) == BATCH_SIZE or idx == df_len - 1:\n",
    "\n",
    "            try:\n",
    "\n",
    "                values = []\n",
    "\n",
    "                for row in data_batch:\n",
    "                    row_value = \", \".join([f\"'{i}'\" for i in row])\n",
    "                    row_value = f'({row_value})'\n",
    "                    values.append(row_value)\n",
    "\n",
    "                values = ', '.join(values)\n",
    "                stmt = f\"\"\"INSERT INTO USER1.{sql_table_name} (\n",
    "                                            id,\n",
    "                                            latitude,\n",
    "                                            longitude,\n",
    "                                            area_in_meters,\n",
    "                                            polygon_coordinates,\n",
    "                                            footprint_source,\n",
    "                                            classification_source,\n",
    "                                            ml_confidence,\n",
    "                                            ml_model,\n",
    "                                            height,\n",
    "                                            height_median,\n",
    "                                            height_mean,\n",
    "                                            height_max,\n",
    "                                            tiff_file,\n",
    "                                            image_url,\n",
    "                                            classification_type,\n",
    "                                            osm_id,\n",
    "                                            osm_name,\n",
    "                                            osm_type,\n",
    "                                            osm_building,\n",
    "                                            osm_other_tags,\n",
    "                                            vida_confidence,\n",
    "                                            urban_split,\n",
    "                                            ghsl_smod,\n",
    "                                            floors,\n",
    "                                            gfa_in_meters,\n",
    "                                            perimeter_in_meters,\n",
    "                                            building_faces,\n",
    "                                            elec_access_percent,\n",
    "                                            elec_consumption_kwh_month,\n",
    "                                            elec_consumption_std_kwh_month\n",
    "                                            ) VALUES {values} \"\"\"\n",
    "                \n",
    "                curs.execute(stmt)\n",
    "                \n",
    "                # print(stmt)\n",
    "                \n",
    "                data_batch = []\n",
    "                last_idx = idx\n",
    "                # break\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Exception occured', e)\n",
    "                excepted_batches.append(data_batch)\n",
    "                data_batch = []\n",
    "                conn = connect_to_db()\n",
    "                curs = conn.cursor()\n",
    "                last_idx = idx\n",
    "\n",
    "                \n",
    "    # if idx > BATCH_SIZE: break\n",
    "\n",
    "print('excepted_batches', len(excepted_batches))\n",
    "\n",
    "excepted = {'excepted_batches': excepted_batches}\n",
    "\n",
    "with open(f\"excepted_batches_{sql_table_name}.json\", \"w\") as outfile: \n",
    "    json.dump(excepted, outfile, default=str)\n",
    "    \n",
    "    \n",
    "print('excepted_rows', len(excepted_rows))\n",
    "\n",
    "excepted_rows = {'excepted_rows': excepted_rows}\n",
    "\n",
    "with open(f\"excepted_rows_{sql_table_name}.json\", \"w\") as outfile: \n",
    "    json.dump(excepted_rows, outfile, default=str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code below is required only if upload above had some issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excepted_batches = json.load(open(f\"excepted_batches_{sql_table_name}.json\"))\n",
    "print(len(excepted_batches['excepted_batches']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to upload one by one in excepted batches\n",
    "\n",
    "exceptions = []\n",
    "# values = []\n",
    "for idx, batch in enumerate(excepted_batches['excepted_batches']):\n",
    "    for row_idx, row in tqdm(enumerate(batch), desc=f'Ingesing data from {idx} batch', total=len(batch)):\n",
    "        \n",
    "        if row_idx >= 0:\n",
    "            try:\n",
    "                row_value = \", \".join([f\"'{i}'\" for i in row])\n",
    "                row_value = f'({row_value})'\n",
    "        # values = ', '.join(values)\n",
    "                \n",
    "                stmt = f\"\"\"INSERT INTO USER1.{sql_table_name} (\n",
    "                                        id,\n",
    "                                        latitude,\n",
    "                                        longitude,\n",
    "                                        area_in_meters,\n",
    "                                        polygon_coordinates,\n",
    "                                        footprint_source,\n",
    "                                        classification_source,\n",
    "                                        ml_confidence,\n",
    "                                        ml_model,\n",
    "                                        height,\n",
    "                                        height_median,\n",
    "                                        height_mean,\n",
    "                                        height_max,\n",
    "                                        tiff_file,\n",
    "                                        image_url,\n",
    "                                        classification_type,\n",
    "                                        osm_id,\n",
    "                                        osm_name,\n",
    "                                        osm_type,\n",
    "                                        osm_building,\n",
    "                                        osm_other_tags,\n",
    "                                        vida_confidence,\n",
    "                                        urban_split,\n",
    "                                        ghsl_smod,\n",
    "                                        floors,\n",
    "                                        gfa_in_meters,\n",
    "                                        perimeter_in_meters,\n",
    "                                        building_faces,\n",
    "                                        elec_access_percent,\n",
    "                                        elec_consumption_kwh_month,\n",
    "                                        elec_consumption_std_kwh_month\n",
    "                                        ) VALUES {row_value} \"\"\"\n",
    "            \n",
    "                curs.execute(stmt)\n",
    "                \n",
    "        # data_batch = []\n",
    "\n",
    "            except Exception as e:\n",
    "                print('Exception occured', e)\n",
    "                exceptions.append(row)\n",
    "            # curs = connect_to_db()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to upload one by one in excepted rows from batches above\n",
    "\n",
    "for exception in exceptions:\n",
    "    try:\n",
    "        row_value = \", \".join([f\"'{i}'\" for i in exception])\n",
    "        row_value = f'({row_value})'\n",
    "        # values = ', '.join(values)\n",
    "\n",
    "        stmt = f\"\"\"INSERT INTO USER1.{sql_table_name} (\n",
    "                                    id,\n",
    "                                                latitude,\n",
    "                                                longitude,\n",
    "                                                area_in_meters,\n",
    "                                                polygon_coordinates,\n",
    "                                                footprint_source,\n",
    "                                                classification_source,\n",
    "                                                ml_confidence,\n",
    "                                                ml_model,\n",
    "                                                height,\n",
    "                                                height_median,\n",
    "                                                height_mean,\n",
    "                                                height_max,\n",
    "                                                tiff_file,\n",
    "                                                image_url,\n",
    "                                                classification_type,\n",
    "                                                osm_id,\n",
    "                                                osm_name,\n",
    "                                                osm_type,\n",
    "                                                osm_building,\n",
    "                                                osm_other_tags,\n",
    "                                                vida_confidence,\n",
    "                                                urban_split,\n",
    "                                                ghsl_smod,\n",
    "                                                floors,\n",
    "                                                gfa_in_meters,\n",
    "                                                perimeter_in_meters,\n",
    "                                                building_faces,\n",
    "                                                elec_access_percent,\n",
    "                                                elec_consumption_kwh_month,\n",
    "                                                elec_consumption_std_kwh_month\n",
    "                                ) VALUES {row_value} \"\"\"\n",
    "\n",
    "        curs.execute(stmt)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
