{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10_S2_TIF_collection\n",
    "### Downloads the Sentinel 2 images for a given country adhering to the MGRS grid standard\n",
    "### This notebook requires a lot of memory!\n",
    "### Please see the last cell, which starts the image retrieval process, several configuration options can be defined there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial configuration\n",
    "#### To start working with this particular notebook, you need to provide necessary credential and settings\n",
    "#### Below is an template of configuration, which is necessary prepare aside of this notebook and copy & paste all content in triple quotes to the next cell's input field\n",
    "    \"\"\"\n",
    "    {\n",
    "    \"COS_ENDPOINT_URL\": \"s3.private.eu-de.cloud-object-storage.appdomain.cloud\",\n",
    "    \"COS_AUTH_ENDPOINT_URL\": \"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    \"COS_APIKEY\": \"xxx\",\n",
    "    \"UTILS_BUCKET\": \"notebook-utils-bucket\",\n",
    "    \"COUNTRY_NAME\": \"Kenya\",\n",
    "    \"GEOTIFF_BUCKET\": \"geotiffs\"\n",
    "    }\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read notebook configuration\n",
    "import getpass\n",
    "import json\n",
    "\n",
    "config_str = getpass.getpass('Enter your prepared config: ')\n",
    "config = json.loads(config_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import ibm_boto3\n",
    "from botocore.client import Config\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "import os\n",
    "import rasterio as rio\n",
    "from io import BytesIO\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from shapely import wkb, wkt\n",
    "import shapely\n",
    "import boto3\n",
    "import random\n",
    "import rioxarray\n",
    "from shapely.prepared import prep\n",
    "import numpy as np\n",
    "import threading\n",
    "from rasterio.mask import mask\n",
    "from skimage import measure as M\n",
    "from rasterio.plot import show\n",
    "import glob\n",
    "import mgrs\n",
    "from datetime import datetime\n",
    "import os\n",
    "from botocore.config import Config\n",
    "from botocore import UNSIGNED\n",
    "from botocore.handlers import disable_signing\n",
    "\n",
    "import traceback\n",
    "\n",
    "m = mgrs.MGRS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the boundary polygon exists for a given country\n",
    "country = config[\"COUNTRY_NAME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_client = ibm_boto3.client(service_name='s3',\n",
    "                              ibm_api_key_id=config[\"COS_APIKEY\"],\n",
    "                              ibm_auth_endpoint=config[\"COS_AUTH_ENDPOINT_URL\"],\n",
    "                              config=Config(signature_version='oauth'),\n",
    "                              endpoint_url=config[\"COS_ENDPOINT_URL\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTINEL2_BUCKET_NAME = 'sentinel-cogs'\n",
    "S3client = boto3.client('s3', region_name='us-west-2', config=Config(signature_version=UNSIGNED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get countries geojson\n",
    "countries_geoJSON_url = 'https://datahub.io/core/geo-countries/r/countries.geojson'\n",
    "countries_geoJSON = requests.get(countries_geoJSON_url).content\n",
    "countries_geoJSON = json.loads(countries_geoJSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract Kenya geojson from counties\n",
    "country_geometry = {}\n",
    "for feature in countries_geoJSON['features']:\n",
    "    if feature['properties']['ADMIN'] == country:\n",
    "        country_geometry['geometry'] = feature['geometry']\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<POLYGON ((41.163 -2.091, 41.155 -2.112, 41.137 -2.115, 41.123 -2.094, 41.12...>,\n",
       " <POLYGON ((35.434 5.004, 35.396 4.926, 35.496 4.926, 35.571 4.904, 35.522 4....>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read geometries to shapely format\n",
    "if country_geometry['geometry']['type'] == 'MultiPolygon':\n",
    "    coordinates = shapely.MultiPolygon(country_geometry['geometry']['coordinates'])\n",
    "elif country_geometry['geometry']['type'] == 'Polygon':\n",
    "    coordinates = shapely.Polygon(country_geometry['geometry']['coordinates'])\n",
    "    \n",
    "coordinates\n",
    "list(coordinates.geoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_off_clouds(TCI_tiff_filename, SCL_tiff_filename):\n",
    "    '''\n",
    "        This functions is aimed for removing cloud related segments from particulat tiff file\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "        with rio.open(SCL_tiff_filename) as src:\n",
    "            \n",
    "            data = src.read(1)\n",
    "            \n",
    "            # mark all unnecessary layers keep only cloud related\n",
    "            try:\n",
    "                data[data == 1] = 0\n",
    "                data[data == 2] = 0\n",
    "                data[data == 4] = 0\n",
    "                data[data == 5] = 0\n",
    "                data[data == 6] = 0\n",
    "                data[data == 7] = 0\n",
    "\n",
    "                data[data == 3] = 1\n",
    "                data[data == 8] = 1\n",
    "                data[data == 9] = 1\n",
    "                data[data == 10] = 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Class assign Exception ocurred for: {SCL_tiff_filename}\")\n",
    "\n",
    "            # retrieve contours of remained united layers\n",
    "            contours = M.find_contours(data, 0.9)\n",
    "            polygons = []\n",
    "            \n",
    "            # convert contours to lat lon representation\n",
    "            for contour in contours:\n",
    "\n",
    "                latlon_coords = []\n",
    "\n",
    "                for coords in contour:\n",
    "                    lon, lat = rio.transform.xy(src.transform, coords[0], coords[1])\n",
    "                    latlon_coords.append([lon, lat])\n",
    "\n",
    "                latlon_coords.append(latlon_coords[0])\n",
    "                latlon_coords = shapely.Polygon(latlon_coords)\n",
    "                \n",
    "                polygons.append(latlon_coords)\n",
    "\n",
    "            print(f\"Cloud polygond were found: {len(polygons)}\")\n",
    "\n",
    "        # remove found cloud polygons from target colorful image\n",
    "        with rio.open(TCI_tiff_filename, 'r') as TCI_src:\n",
    "            \n",
    "            if len(polygons) == 0:\n",
    "                print(\"Zero polygons were found return nonmasked TCI\")\n",
    "\n",
    "                return TCI_src.read(), TCI_src.meta\n",
    "            \n",
    "            out_image, _ = rio.mask.mask(TCI_src, polygons, invert=True, all_touched=True, nodata=0)\n",
    "            \n",
    "            os.remove(TCI_tiff_filename)\n",
    "            os.remove(SCL_tiff_filename)\n",
    "\n",
    "            # image = np.array(out_image)\n",
    "            # image[image == 0] = np.nan\n",
    "            \n",
    "            return out_image, TCI_src.meta\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Exception occured: {e} for: {SCL_tiff_filename}\")\n",
    "        print(traceback.format_exc())\n",
    "        \n",
    "        return [], TCI_src.meta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find all the MGRS tile names for given country polygon\n",
    "MGRS_tiles = []\n",
    "\n",
    "for polygon in coordinates.geoms:\n",
    "    \n",
    "    coordinates_list = polygon.exterior.coords._coords\n",
    "    for xy in coordinates_list:\n",
    "        MGRS_tiles.append(m.toMGRS(xy[1], xy[0], MGRSPrecision=0))\n",
    "\n",
    "        \n",
    "    latmin, lonmin, latmax, lonmax = polygon.bounds\n",
    "    resolution = 0.05\n",
    "    for lat in np.arange(latmin, latmax, resolution):\n",
    "        for lon in np.arange(lonmin, lonmax, resolution):\n",
    "            MGRS_tiles.append(m.toMGRS(round(lon,4), round(lat,4), MGRSPrecision=0))\n",
    "        \n",
    "MGRS_tiles = list(set(MGRS_tiles))\n",
    "\n",
    "len(MGRS_tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject coordinate reference system from (x, y) pixels to (lat, lon) coordinates\n",
    "def reproject_tif_CRS(filename: str):\n",
    "    rds = rioxarray.open_rasterio(filename)\n",
    "    rds_4326 = rds.rio.reproject(\"EPSG:4326\")\n",
    "    rds_4326.rio.to_raster(filename, compress=\"DEFLATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download defined Sentinel2 TCI (True Color Image) and their according SCL (Scene Classification Layer) products from S3 bucket\n",
    "def download_products(partial_tile_name):\n",
    "    # bands = ['B02.tif', 'B03.tif', 'B04.tif']\n",
    "    bands = ['TCI.tif']\n",
    "\n",
    "    tiffs = []\n",
    "    SCL_filename = None\n",
    "    bucket_objects = [obj['Key'] for obj in S3client.list_objects(Bucket=SENTINEL2_BUCKET_NAME, Prefix=partial_tile_name)['Contents']]\n",
    "                \n",
    "    for obj_name in bucket_objects:\n",
    "        if (str(obj_name[-7:]) in bands):\n",
    "            tiffs.append(obj_name)\n",
    "\n",
    "        elif (str(obj_name[-7:]) in ['SCL.tif']):\n",
    "            SCL_filename = obj_name\n",
    "    \n",
    "    # download SCL layer and reproject its coordinate reference system\n",
    "    filename = tiffs[0].split('/')[-2]\n",
    "    SCL_file_path = f'tiles/{filename}_SCL.tif'\n",
    "    S3client.download_file(SENTINEL2_BUCKET_NAME, SCL_filename, SCL_file_path)\n",
    "    reproject_tif_CRS(SCL_file_path)  \n",
    "\n",
    "\n",
    "    # download TCI layers and reproject its coordinate reference systemd \n",
    "    TCI_file_path = f'tiles/{filename}_TCI.tif'\n",
    "    if 'TCI.tif' in bands:\n",
    "        for tif in tiffs:\n",
    "            S3client.download_file(SENTINEL2_BUCKET_NAME, tif, TCI_file_path)\n",
    "            reproject_tif_CRS(TCI_file_path)\n",
    "        \n",
    "        return TCI_file_path, SCL_file_path\n",
    "    \n",
    "\n",
    "    # if bands were defined instead TCI download them combine and save\n",
    "    tiles = []\n",
    "    for tif in tqdm(tiffs, desc=f\"Downloading product {tiffs[0].split('/')[-2]}\", total=len(tiffs)):\n",
    "        fileobj = S3client.get_object(Bucket=SENTINEL2_BUCKET_NAME, Key=tif)['Body']\n",
    "        tile = rio.open(BytesIO(fileobj.read()), 'r')\n",
    "        tiles.append(tile)\n",
    "\n",
    "    # fileobj = S3client.get_object(Bucket=SENTINEL2_BUCKET_NAME, Key=SCL_filename)['Body']\n",
    "    \n",
    "    \n",
    "    filename = tiffs[0].split('/')[-2]\n",
    "    tif_file =f'{filename}.tif'\n",
    "    tif_destination = f\"tiles/{tif_file}\"\n",
    "\n",
    "    colorful_tile = rio.open(tif_destination, 'w', driver='Gtiff',\n",
    "                            width=tiles[0].width, height=tiles[0].height,\n",
    "                            count=3,\n",
    "                            crs=tiles[0].crs,\n",
    "                            transform=tiles[0].transform,\n",
    "                            photometric=\"RGB\", \n",
    "                            compress=\"DEFLATE\", \n",
    "                            bigtiff=\"IF_NEEDED\", \n",
    "                            tiled=True, \n",
    "                            blockxsize=256, \n",
    "                            blockysize=256,\n",
    "                            dtype='uint8')\n",
    "\n",
    "    for idx, tile in enumerate(tiles):\n",
    "        colorful_tile.write(tile.read(1), idx + 1)\n",
    "    \n",
    "    colorful_tile.close()\n",
    "    reproject_tif_CRS(tif_destination)\n",
    "\n",
    "    return tif_destination, SCL_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folder for saved numpy arrays\n",
    "masked_tiles_np_files_folder = 'masked_tiles_np_files'\n",
    "\n",
    "if not os.path.exists(masked_tiles_np_files_folder):\n",
    "    os.makedirs(masked_tiles_np_files_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_product(product, masked_tiles_filenames, tiff_metadata):\n",
    "    tci_tif_name, scl_tif_name = download_products(product)\n",
    "    masked_tile, tiff_meta = mask_off_clouds(tci_tif_name, scl_tif_name)\n",
    "\n",
    "    if len(masked_tile) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        try:\n",
    "            filepath = f\"{masked_tiles_np_files_folder}/{tci_tif_name.replace('.tif', '').replace('tiles/', '')}.npy\"\n",
    "            masked_tile = np.array(masked_tile).astype(np.float64)\n",
    "            np.save(filepath, masked_tile)\n",
    "            masked_tiles_filenames.append(filepath)\n",
    "            tiff_metadata.append(tiff_meta)\n",
    "        except Exception as e:\n",
    "            print('Numpy saving error occurred', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tiles(\n",
    "        MGRS_selected_tiles: list, \n",
    "        products_to_process: int,\n",
    "        cloudy_percentage: int,\n",
    "        years_range: list,\n",
    "        months_range: list\n",
    "        ):\n",
    "    \n",
    "    errors = []\n",
    "    skippped_tiles = []\n",
    "\n",
    "#     tiles = []\n",
    "\n",
    "    for tile_idx, tile in enumerate(MGRS_selected_tiles):\n",
    "\n",
    "        print(f\"Processing tile: {tile} | {tile_idx+1} of {len(MGRS_selected_tiles)}\")\n",
    "        t1 = time.time()\n",
    "\n",
    "        data_coverage_2b = {}\n",
    "        cloud_coverage_percentages_2b = {}\n",
    "\n",
    "        no_data_percentages_2a = {}\n",
    "        cloud_coverage_percentages_2a = {}\n",
    "        \n",
    "        for year in years_range:\n",
    "        \n",
    "            for month in months_range:\n",
    "                \n",
    "                partial_tile_name = f\"sentinel-s2-l2a-cogs/{tile[0:2]}/{tile[2:3]}/{tile[3:5]}/{year}/{month}\"\n",
    "                \n",
    "                try:\n",
    "            \n",
    "                    bucket_objects = [obj['Key'] for obj in S3client.list_objects(Bucket=SENTINEL2_BUCKET_NAME, Prefix=partial_tile_name)['Contents']]\n",
    "                    \n",
    "                    for obj in bucket_objects:\n",
    "                        if \"L2A.json\" in obj:\n",
    "                            json_body = S3client.get_object(Bucket=SENTINEL2_BUCKET_NAME, Key=obj)['Body']\n",
    "                            tile_info_metadata_json = json.loads(json_body.read().decode(\"utf-8\"))\n",
    "                            \n",
    "                            key = '/'.join(obj.split('/')[:-1])\n",
    "                            version = tile_info_metadata_json['stac_version']\n",
    "                            if version == \"1.0.0\":\n",
    "                                if \"S2B_\" in obj:\n",
    "                                    try:\n",
    "                                        created = datetime.strptime(tile_info_metadata_json[\"properties\"][\"created\"], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "                                        no_data_percentage = float(tile_info_metadata_json[\"properties\"][\"s2:nodata_pixel_percentage\"])\n",
    "                                        tile_cloudy_percentage = float(tile_info_metadata_json[\"properties\"][\"eo:cloud_cover\"])\n",
    "                                        \n",
    "                                    except Exception as e:\n",
    "                                        print(f'S2B ver: {version} | Exception occured: {e} for product {obj}')\n",
    "                                        pass\n",
    "\n",
    "                                    if (no_data_percentage <= 2):\n",
    "                                        data_coverage_2b[key] = no_data_percentage\n",
    "                                        \n",
    "                                    if (tile_cloudy_percentage <= cloudy_percentage):\n",
    "                                        cloud_coverage_percentages_2b[key] = tile_cloudy_percentage\n",
    "\n",
    "                                if \"S2A_\" in obj:\n",
    "\n",
    "                                    try:\n",
    "                                        created = datetime.strptime(tile_info_metadata_json[\"properties\"][\"created\"], \"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "                                        no_data_percentage = tile_info_metadata_json[\"properties\"][\"s2:nodata_pixel_percentage\"]\n",
    "                                        tile_cloudy_percentage = tile_info_metadata_json[\"properties\"][\"eo:cloud_cover\"]\n",
    "                                        \n",
    "                                    except Exception as e:\n",
    "                                        print(f'S2A ver: {version} | Exception occured: {e} for product {obj}')\n",
    "                                        pass\n",
    "                                    \n",
    "                                    if (no_data_percentage <= 2):\n",
    "                                        no_data_percentages_2a[key] = no_data_percentage\n",
    "                                            \n",
    "                                    if (tile_cloudy_percentage <= cloudy_percentage):\n",
    "                                        cloud_coverage_percentages_2a[key] = tile_cloudy_percentage\n",
    "                            \n",
    "                            elif version == \"1.0.0-beta.2\":\n",
    "\n",
    "                                if \"S2B_\" in obj:\n",
    "                                    try:\n",
    "\n",
    "                                        if tile_info_metadata_json[\"properties\"]['sentinel:valid_cloud_cover'] != False:\n",
    "                                            created = datetime.strptime(tile_info_metadata_json[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                                            no_data_percentage = float(tile_info_metadata_json[\"properties\"][\"sentinel:data_coverage\"])\n",
    "                                            tile_cloudy_percentage = float(tile_info_metadata_json[\"properties\"][\"eo:cloud_cover\"])\n",
    "                                        \n",
    "                                    except Exception as e:\n",
    "                                        print(f'S2B ver: {version} | Exception occured: {e} for product {obj}')\n",
    "                                        pass\n",
    "\n",
    "                                    if (no_data_percentage >= 5):\n",
    "                                        # print(version, key, created)\n",
    "                                        data_coverage_2b[key] = 45 - no_data_percentage\n",
    "                                        \n",
    "                                    if (tile_cloudy_percentage <= cloudy_percentage):\n",
    "                                        cloud_coverage_percentages_2b[key] = tile_cloudy_percentage\n",
    "\n",
    "                                if \"S2A_\" in obj:\n",
    "\n",
    "                                    try:\n",
    "                                        if tile_info_metadata_json[\"properties\"]['sentinel:valid_cloud_cover'] != False:\n",
    "                                            created = datetime.strptime(tile_info_metadata_json[\"properties\"][\"datetime\"], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                                            no_data_percentage = tile_info_metadata_json[\"properties\"][\"sentinel:data_coverage\"]\n",
    "                                            tile_cloudy_percentage = tile_info_metadata_json[\"properties\"][\"eo:cloud_cover\"]\n",
    "                                        \n",
    "                                    except Exception as e:\n",
    "                                        print(f'S2A ver: {version} | Exception occured: {e} for product {obj}')\n",
    "                                        pass\n",
    "                                    \n",
    "                                    if (no_data_percentage >= 4):\n",
    "                                        no_data_percentages_2a[key] = 45 - no_data_percentage\n",
    "                                            \n",
    "                                    if (tile_cloudy_percentage <= cloudy_percentage):\n",
    "                                        cloud_coverage_percentages_2a[key] = tile_cloudy_percentage\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    \n",
    "                    errors.append(partial_tile_name)\n",
    "                    # print(f\"Esception {e} occured /for: {partial_tile_name}\")\n",
    "\n",
    "        cloud_coverage_percentages_sorted_2b = sorted(cloud_coverage_percentages_2b.items(), key=lambda x: x[1])\n",
    "        data_coverage_percentages_sorted_2b = sorted(data_coverage_2b.items(), key=lambda x:x[1])\n",
    "\n",
    "        # data_coverage_percentages_sorted_2b.reverse()\n",
    "\n",
    "        if len(data_coverage_percentages_sorted_2b) == 0:\n",
    "            data_coverage_percentages_sorted_2b = cloud_coverage_percentages_sorted_2b[:products_to_process]\n",
    "        if len(cloud_coverage_percentages_sorted_2b) == 0:\n",
    "            cloud_coverage_percentages_sorted_2b = data_coverage_percentages_sorted_2b[:products_to_process]\n",
    "\n",
    "        matched_products_2b = []\n",
    "\n",
    "        for i in cloud_coverage_percentages_sorted_2b:\n",
    "            if i[0] in [j[0] for j in data_coverage_percentages_sorted_2b]:\n",
    "                matched_products_2b.append(i[0])\n",
    "\n",
    "        print('matched_products_2b', len(matched_products_2b))\n",
    "\n",
    "        matched_products_2b = matched_products_2b[:products_to_process]\n",
    "\n",
    "        cloud_coverage_percentages_sorted_2a = sorted(cloud_coverage_percentages_2a.items(), key=lambda x: x[1])\n",
    "        no_data_percentages_sorted_2a = sorted(no_data_percentages_2a.items(), key=lambda x:x[1])\n",
    "\n",
    "        if len(no_data_percentages_sorted_2a) == 0:\n",
    "            no_data_percentages_sorted_2a = cloud_coverage_percentages_sorted_2a[:products_to_process]\n",
    "        if len(cloud_coverage_percentages_sorted_2a) == 0:\n",
    "            cloud_coverage_percentages_sorted_2a = no_data_percentages_sorted_2a[:products_to_process]\n",
    "\n",
    "        matched_products_2a = []\n",
    "\n",
    "        for i in cloud_coverage_percentages_sorted_2a:\n",
    "            if i[0] in [j[0] for j in no_data_percentages_sorted_2a]:\n",
    "                matched_products_2a.append(i[0])\n",
    "        \n",
    "        print('matched_products_2a', len(matched_products_2a)) \n",
    "\n",
    "        matched_products_2a = matched_products_2a[:products_to_process]\n",
    "\n",
    "        matched_products = matched_products_2a + matched_products_2b\n",
    "\n",
    "        if len(matched_products) > 0:\n",
    "\n",
    "            masked_tile_files = []\n",
    "\n",
    "            tiff_metadata = []\n",
    "            threads= []\n",
    "\n",
    "            for idx, product in enumerate(matched_products, start=1):\n",
    "                thread = threading.Thread(target=process_product, args=(product, masked_tile_files, tiff_metadata, ))\n",
    "                threads.append(thread)\n",
    "\n",
    "            # for idx, product in enumerate(matched_products_2b, start=1):\n",
    "            #     thread = threading.Thread(target=process_product, args=(product, masked_tiles_2b, tiff_metadata, ))\n",
    "            #     threads.append(thread)\n",
    "\n",
    "            for thread in threads:\n",
    "                thread.start()\n",
    "\n",
    "            for tidx, thread in enumerate(threads, start=1):\n",
    "                thread.join()\n",
    "                \n",
    "            print('masked_tiles', len(masked_tile_files))\n",
    "\n",
    "            # memory optimized \n",
    "            \n",
    "            # load first np array image product\n",
    "            mean_of_tiffs = np.load(masked_tile_files[0])\n",
    "            # replace 0 with np.nan values for nanmean func\n",
    "            mean_of_tiffs[mean_of_tiffs == 0] = np.nan\n",
    "            \n",
    "            # rest arrays to process\n",
    "            masked_tile_files_to_process = masked_tile_files[1:]\n",
    "            \n",
    "            for filepath in tqdm(masked_tile_files_to_process, desc='Calculating nanmean for tiles', total=len(masked_tile_files_to_process)):\n",
    "                \n",
    "                # load and remove .npy from memory\n",
    "                tile_loaded = np.load(filepath)\n",
    "                os.remove(filepath)\n",
    "                # replace 0 with np.nan values for nanmean func\n",
    "                tile_loaded[tile_loaded == 0] = np.nan\n",
    "                \n",
    "                # assemble ongoing array and processed array in np array\n",
    "                tiles_to_process = np.array([mean_of_tiffs, tile_loaded])\n",
    "\n",
    "                # clear from memory\n",
    "                del tile_loaded\n",
    "                \n",
    "                # calculate mean of non nan values\n",
    "                mean_of_tiffs = np.nanmean(tiles_to_process, axis=0)\n",
    "\n",
    "            # convert as int16 type for raster image\n",
    "            mean_of_tiffs = mean_of_tiffs.astype(np.int16)\n",
    "\n",
    "            # save to raster .tif fi;e\n",
    "            with rio.open(f'cloudless_tiffs/{tile}_cloudless.tif', 'w', **tiff_metadata[0]) as dest:\n",
    "                dest.write(mean_of_tiffs)\n",
    "            \n",
    "            # upload to bucket\n",
    "            try:\n",
    "                res=cos_client.upload_file(Filename=f'cloudless_tiffs/{tile}_cloudless.tif', Bucket='s2lab2-temp',Key=f\"{tile}_cloudless.tif\")\n",
    "                os.remove(f'cloudless_tiffs/{tile}_cloudless.tif')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(Exception, e)\n",
    "            else:\n",
    "                print(f'{tile}_cloudless.tif Uploaded')\n",
    "\n",
    "            del mean_of_tiffs\n",
    "            \n",
    "            print(\"Garbage collector: collected\",\n",
    "                      \"%d objects.\" % gc.collect())\n",
    "                \n",
    "        print(f'TIFF tile processing time: {time.strftime(\"%H:%M:%S\", time.gmtime(int(time.time() - t1)))}')\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually define MGRS tiles to process, set this list before starting the computation\n",
    "MGRS_selected = [\n",
    "   # '44QMD',\n",
    "   '44QLE',\n",
    "   '43QHV',\n",
    "   '43QHB',\n",
    "   '43QCD'\n",
    "]\n",
    "\n",
    "\n",
    "# Run main function\n",
    "download_tiles(\n",
    "    MGRS_selected,\n",
    "    products_to_process = 4, # amount of product to process 4 is optimal value to obtain clear image\n",
    "    cloudy_percentage = 15,  #maximal cloud coverage percentage per product\n",
    "    years_range = [2023, 2024], # years range can be from 2017 (its when Sentinel2B was launched)\n",
    "    months_range = [7, 8, 9, 10, 11, 12] # desired months range from 1 to 12\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
